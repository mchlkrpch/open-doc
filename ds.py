import csv
import re
from pathlib import Path
from typing import List, Dict, Tuple
from bs4 import BeautifulSoup
import PyPDF2
import os
import pandas as pd
from dataclasses import dataclass

@dataclass
class Row:
	tp: str
	txt: str
	src: str
	q: str
	a: str
	set: str
	domain: str

	@classmethod
	def from_pandas_row(cls, row: pd.Series):
		return cls(**{
			key: row.get(key, None)
			for key in ['tp', 'txt', 'src', 'q', 'a', 'set', 'domain']})

class OpenDocQA:
	def __init__(self, fld_pt: str):
		"""
		Initialize QA Dataset for RAG evaluation.
		
		Args:
			csv_path: Path to CSV file containing questions and answers
			document_path: Optional path to source document (HTML/PDF)
		"""
		pt = Path(fld_pt)
		self.cur_field = ''
		# whole questions and answerss dataset
		self.df = pd.DataFrame()
		# local paths to documents
		self.doc_pts: dict[str,str] = {}
		# all spheres and sets in dataset
		self._partition: dict[str, set[str]] = {}

		for f in os.listdir(pt):
			if f.endswith(".csv"):
				df = pd.read_csv(pt / Path(f))
				self.df = pd.concat([self.df, df], ignore_index=True)

				# add all paths of documents
				set_of_links: str = list(set(df['src']))
				for link in set_of_links:
					if not pd.isnull(link) and not link.startswith('http'):
						self.doc_pts[link] = (pt / Path(link)).resolve()

				# add all domains and sets
				for domain in set(df['domain']):
					if domain not in self._partition:
						if not pd.isnull(domain):
							self._partition[domain] = set(df['set'])
					else:
						options = set(df['set'])
						for o in options:
							if not pd.isnull(o):
								self._partition[domain].add(o)

	def __getattr__(self, name):
		if name in self._partition:
				return DomainAccessor(self, name)
		raise AttributeError(f"'{self.__class__.__name__}' object has no attribute '{name}'")
	
	def __getitem__(self, i: int):
		return Row.from_pandas_row(self.df.iloc[i])

	def __str__(self):
		reprstr: str = f"OPEN-DOC QA-dataset\n\n"
		for domain in self._partition.keys():
			reprstr += f"{domain}:\n"
			for s in self._partition[domain]:
				reprstr += f"  {len(eval(f"qa.{domain}.{s}"))} questions - {s}\n"
		return reprstr
	
	def load_document(self, document_path: str) -> None:
		"""
		Load and extract text from document (HTML or PDF)
		
		Args:
			document_path: Path to document file
		"""
		path = Path(document_path)
		if not path.exists():
			raise FileNotFoundError(f"Document not found: {document_path}")
		
		if path.suffix.lower() == '.html':
			self._load_html_document(path)
		elif path.suffix.lower() == '.pdf':
			self._load_pdf_document(path)
		else:
			raise ValueError("Unsupported document format. Only HTML and PDF are supported.")
	
	def _load_html_document(self, path: Path) -> None:
		"""Extract all text from HTML document"""
		try:
			with open(path, 'r', encoding='utf-8') as file:
				soup = BeautifulSoup(file, 'html.parser')
				# Remove script and style elements
				for script in soup(["script", "style"]):
					script.decompose()
				self.document_text = soup.get_text(separator=' ', strip=True)
				# Clean up excessive whitespace
				self.document_text = re.sub(r'\s+', ' ', self.document_text)
		except Exception as e:
			raise ValueError(f"Error processing HTML document: {str(e)}")
	
	def _load_pdf_document(self, path: Path) -> None:
		"""Extract all text from PDF document"""
		try:
			with open(path, 'rb') as file:
				reader = PyPDF2.PdfReader(file)
				text = []
				for page in reader.pages:
					text.append(page.extract_text())
				self.document_text = '\n'.join(text)
				# Clean up excessive whitespace
				self.document_text = re.sub(r'\s+', ' ', self.document_text)
		except Exception as e:
			raise ValueError(f"Error processing PDF document: {str(e)}")
	
	def evaluate_rag(self, generated_answers: List[str], metrics: List[str] = ['exact_match', 'f1']) -> Dict[str, List[float]]:
		"""
		Evaluate RAG performance against reference answers
		
		Args:
			generated_answers: List of answers generated by RAG system
			metrics: List of metrics to compute ('exact_match', 'f1', 'bleu', 'rouge')
			
		Returns:
			Dictionary with metric names as keys and lists of scores as values
		"""
		if len(generated_answers) != len(self.reference_answers):
			raise ValueError("Number of generated answers must match number of reference answers")
		
		results = {metric: [] for metric in metrics}
		
		for gen_answer, ref_answer in zip(generated_answers, self.reference_answers):
			if 'exact_match' in metrics:
				results['exact_match'].append(self._exact_match(gen_answer, ref_answer))
			if 'f1' in metrics:
				results['f1'].append(self._f1_score(gen_answer, ref_answer))
			if 'bleu' in metrics:
				results['bleu'].append(self._bleu_score(gen_answer, ref_answer))
			if 'rouge' in metrics:
				results['rouge'].append(self._rouge_score(gen_answer, ref_answer))
		
		return results
	
	def _exact_match(self, gen_answer: str, ref_answer: str) -> float:
		"""Compute exact match score (1 if answers match exactly, 0 otherwise)"""
		return float(gen_answer.strip().lower() == ref_answer.strip().lower())
	
	def _f1_score(self, gen_answer: str, ref_answer: str) -> float:
		"""Compute F1 score between generated and reference answer"""
		gen_tokens = set(gen_answer.lower().split())
		ref_tokens = set(ref_answer.lower().split())
		
		if not gen_tokens or not ref_tokens:
			return 0.0
		
		common_tokens = gen_tokens & ref_tokens
		precision = len(common_tokens) / len(gen_tokens)
		recall = len(common_tokens) / len(ref_tokens)
		
		if (precision + recall) == 0:
			return 0.0
		
		return 2 * (precision * recall) / (precision + recall)
	
	def _bleu_score(self, gen_answer: str, ref_answer: str) -> float:
		"""Compute BLEU score (simplified version)"""
		# Note: For production use, consider using nltk's bleu_score
		gen_words = gen_answer.lower().split()
		ref_words = ref_answer.lower().split()
		
		if not gen_words or not ref_words:
			return 0.0
		
		common_words = set(gen_words) & set(ref_words)
		return len(common_words) / len(ref_words)
	
	def _rouge_score(self, gen_answer: str, ref_answer: str) -> float:
		"""Compute ROUGE-L score (simplified version)"""
		# Note: For production use, consider using rouge-score package
		gen_words = gen_answer.lower().split()
		ref_words = ref_answer.lower().split()
		
		if not gen_words or not ref_words:
			return 0.0
		
		# Find longest common subsequence
		lcs_length = self._lcs(gen_words, ref_words)
		recall = lcs_length / len(ref_words)
		precision = lcs_length / len(gen_words)
		
		if (precision + recall) == 0:
			return 0.0
		
		return 2 * (precision * recall) / (precision + recall)
	
	def _lcs(self, a: List[str], b: List[str]) -> int:
		"""Compute length of longest common subsequence"""
		lengths = [[0] * (len(b)+1) for _ in range(len(a)+1)]
		for i, x in enumerate(a):
			for j, y in enumerate(b):
				if x == y:
					lengths[i+1][j+1] = lengths[i][j] + 1
				else:
					lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])
		return lengths[-1][-1]
	
	def __len__(self) -> int:
		"""Number of QA pairs in the dataset"""
		return len(self.df)

class DomainAccessor:
	def __init__(self, qa_instance, domain):
		self.qa = qa_instance
		self.domain = domain
	
	def __getattr__(self, name):
		if name in self.qa._partition[self.domain]:
			return self.qa.df[
				(self.qa.df['domain'] == self.domain) & 
				(self.qa.df['set'] == name)]
		raise AttributeError(f"Domain '{self.domain}' has no set '{name}'")